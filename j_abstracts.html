
<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-software">1</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and K.&nbsp;Usevich.
 Software for weighted structured low-rank approximation.
 <em>J. Comput. Appl. Math.</em>, 256:278-292, 2014.
[&nbsp;<a href="j_bib.html#slra-software">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.cam.2013.07.048">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/slra.pdf">pdf</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/recent-publications.html">.html</a>&nbsp;]
<blockquote>
A software package is presented that computes locally optimal solutions to low-rank approximation problems with the following features:
<p><ul>
<em>mosaic Hankel structure</em> constraint on the approximating matrix,
<em>weighted 2-norm</em> approximation criterion,
<em>fixed elements</em> in the approximating matrix,
<em>missing elements</em> in the data matrix, and
<em>linear constraints</em> on an approximating matrix's left kernel basis.
</ul>
It implements a variable projection type algorithm and allows the user to choose standard local optimization methods for the solution of the parameter optimization problem. For an <em>m</em>&#215;<em>n</em> data matrix, with <em>n</em>&gt;<em>m</em>, the computational complexity of the cost function and derivative evaluation is&nbsp;<em>O</em>(<em>m</em><sup>2</sup><em>n</em>). The package is suitable for applications with <em>n</em><em>m</em>. In statistical estimation and data modeling-the main application areas of the package-<em>n</em><em>m</em> corresponds to modeling of large amount of data by a low-complexity model. Performance results on benchmark system identification problems from the database DAISY and approximate common divisor problems are presented.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="overview">2</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Recent progress on variable projection methods for structured
  low-rank approximation.
 <em>Signal Processing</em>, 96PB:406-419, 2014.
[&nbsp;<a href="j_bib.html#overview">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.sigpro.2013.09.021">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/overview.pdf">pdf</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/recent-publications.html">.html</a>&nbsp;]
<blockquote>
Rank deficiency of a data matrix is equivalent to the existence of an exact linear model for the data. For the purpose of linear static modeling, the matrix is unstructured and the corresponding modeling problem is an approximation of the matrix by another matrix of a lower rank. In the context of linear time-invariant dynamic models, the appropriate data matrix is Hankel and the corresponding modeling problems becomes structured low-rank approximation. Low-rank approximation has applications in: system identification; signal processing, machine learning, and computer algebra, where different types of structure and constraints occur. This paper gives an overview of recent progress in efficient local optimization algorithms for solving weighted mosaic-Hankel structured low-rank approximation problems. In addition, the data matrix may have missing elements and elements may be specified as exact. The described algorithms are implemented in a publicly available software package. Their application to system identification, approximate common divisor, and data-driven simulation problems is described in this paper and is illustrated by reproducible simulation examples. As a data modeling paradigm the low-rank approximation setting is closely related to the the behavioral approach in systems and control, total least squares, errors-in-variables modeling, principal component analysis, and rank minimization.
</blockquote>
<p>
</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="UM12-aut">3</a>]
</td>
<td class="bibtexitem">
K.&nbsp;Usevich and I.&nbsp;Markovsky.
 Optimization on a Grassmann manifold with application to system
  identification.
 <em>Automatica</em>, 2014.
[&nbsp;<a href="j_bib.html#UM12-aut">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2014.04.010">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~kusevich/preprints/usevich_markovsky_aut2012.pdf">pdf</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~kusevich/preprints.html">.html</a>&nbsp;]
<blockquote>
In this paper, we consider the problem of optimization of a cost function on a Grassmann manifold. This problem appears in system identification in the behavioral setting, which is a structured low-rank approximation problem. We develop a new method for local optimization on the Grassmann manifold with switching coordinate charts. This method reduces the optimization problem on the manifold to an optimization problem in a bounded domain of an Euclidean space. Our experiments show that this method is competitive with state- of-the-art retraction-based methods. Compared to retraction-based methods, the proposed method allows to incorporate easily an arbitrary optimization method for solving the optimization subproblem in the Euclidean space.
</blockquote>
<p><blockquote>
Keywords: system identification, over-parameterized models, Grassmann manifold, coordinate charts, structured low-rank approximation, optimization
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="pltv">4</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky, J.&nbsp;Goos, K.&nbsp;Usevich, and R.&nbsp;Pintelon.
 Realization and identification of autonomous linear periodically
  time-varying systems.
 <em>Automatica</em>, 2014.
[&nbsp;<a href="j_bib.html#pltv">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.automatica.2014.04.003">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/pltv-rev3.pdf">pdf</a>&nbsp;]
<blockquote>
Subsampling of a linear periodically time-varying system results in a collection of linear time-invariant systems with common poles. This key fact, known as &ldquo;lifting&rdquo;, is used in a two step realization method. The first step is the realization of the time-invariant dynamics (the lifted system). Computationally, this step is a rank-revealing factorization of a block-Hankel matrix. The second step derives a state space representation of the periodic time-varying system. It is shown that no extra computations are required in the second step. The computational complexity of the overall method is therefore equal to the complexity for the realization of the lifted system. A modification of the realization method is proposed, which makes the complexity independent of the parameter variation period. Replacing the rank-revealing factorization in the realization algorithm by structured low-rank approximation yields a maximum likelihood identification method. Existing methods for structured low-rank approximation are used to identify efficiently linear periodically time-varying system. These methods can deal with missing data.

</blockquote>
<p><blockquote>
Keywords: linear periodically time-varying systems, lifting, realization, Kung's algorithm, Hankel low-rank approximation, maximum likelihood estimation.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-ext">5</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and K.&nbsp;Usevich.
 Structured low-rank approximation with missing data.
 <em>SIAM J. Matrix Anal. Appl.</em>, pages 814-830, 2013.
[&nbsp;<a href="j_bib.html#slra-ext">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/120883050">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/slra-ext.pdf">pdf</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/recent-publications.html">.html</a>&nbsp;]
<blockquote>
We consider low-rank approximation of affinely structured matrices with missing elements. The method proposed is based on reformulation of the problem as inner and outer optimization. The inner minimization is a singular linear least-norm problem and admits an analytic solution. The outer problem is a nonlinear least squares problem and is solved by local optimization methods: minimization subject to quadratic equality constraints and unconstrained minimization with regularized cost function. The method is generalized to weighted low-rank approximation with missing values and is illustrated on approximate low-rank matrix completion, system identification, and data-driven simulation problems. An extended version of the paper is a literate program, implementing the method and reproducing the presented results.
</blockquote>
<p><blockquote>
Keywords: low-rank approximation, missing data, variable projection, system identification, approximate matrix completion.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ident">6</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 A software package for system identification in the behavioral
  setting.
 <em>Control Engineering Practice</em>, 21:1422-1436, 2013.
[&nbsp;<a href="j_bib.html#ident">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.conengprac.2013.06.010">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/ident.pdf">pdf</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/recent-publications.html">.html</a>&nbsp;]
<blockquote>
An identification problem with no a priori separation of the variables into inputs and outputs and representation invariant approximation criterion is considered. The model class consists of linear time-invariant systems of bounded complexity and the approximation criterion is the minimum of a weighted 2-norm distance between the given time series and a time series that is consistent with the model. The problem is equivalent to and is solved as a mosaic-Hankel structured low-rank approximation problem. Software implementing the approach is developed and tested on benchmark problems. Additional nonstandard features of the software are specification of exact and missing variables and identification from multiple experiments.
</blockquote>
<p><blockquote>
Keywords: system identification; model reduction; behavioral approach; missing data; low-rank approximation; total least squares; reproducible research; DAISY.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="slra-efficient">7</a>]
</td>
<td class="bibtexitem">
K.&nbsp;Usevich and I.&nbsp;Markovsky.
 Variable projection for affinely structured low-rank approximation in
  weighted 2-norms.
 <em>J. Comput. Appl. Math.</em>, 2013.
[&nbsp;<a href="j_bib.html#slra-efficient">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.cam.2013.04.034">DOI</a>&nbsp;| 
<a href="http://arxiv.org/pdf/1211.3938v2">pdf</a>&nbsp;| 
<a href="http://arxiv.org/abs/1211.3938">http</a>&nbsp;]
<blockquote>
The structured low-rank approximation problem for general affine structures, weighted 2-norms and fixed elements is considered. The variable projection principle is used to reduce the dimensionality of the optimization problem. Algorithms for evaluation of the cost function, the gradient and an approximation of the Hessian are developed. For <em>m</em>&#215;<em>n</em> mosaic Hankel matrices the algorithms have complexity <em>O</em>(<em>m</em><sup>2</sup><em>n</em>).
</blockquote>
<p><blockquote>
Keywords: Structured low-rank approximation; Variable projection; Mosaic Hankel matrices; Weighted 2-norm; Fixed elements; Computational complexity
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="Markovsky13CEP-software">8</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 A software package for system identification in the behavioral
  setting.
 <em>Control Engineering Practice</em>, 21:1422-1436, 2013.
[&nbsp;<a href="j_bib.html#Markovsky13CEP-software">bib</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="LMFR12">9</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Le, I.&nbsp;Markovsky, C.&nbsp;Freeman, and E.&nbsp;Rogers.
 Recursive identification of Hammerstein systems with application to
  electrically stimulated muscle.
 <em>Control Engineering Practice</em>, 20(4):386-396, 2012.
[&nbsp;<a href="j_bib.html#LMFR12">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.conengprac.2011.08.001">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/271583/3/zoe2-published.pdf">pdf</a>&nbsp;]
<blockquote>
Two methods for recursive identification of Hammerstein systems are presented. In the first method, recursive least squares algorithm is applied to an overparameterized representation of the Hammerstein model and a rank-1 approximation is used to recover the linear and nonlinear parameters from the estimated overparameterized representation. In the second method, the linear and nonlinear parameters are recursively estimated in an alternate manner. Numerical example with simulated data and experimental data from human muscles show the superiority of second method.
</blockquote>
<p><blockquote>
Keywords: recursive identification; Hammerstein system; muscle model; functional electrical stimulation.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="complex-ls">10</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 On the complex least squares problem with constrained phase.
 <em>SIAM J. Matrix Anal. Appl.</em>, 32(3):987-992, 2011.
[&nbsp;<a href="j_bib.html#complex-ls">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1137/110826497">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/272534/1/complex-ls.pdf">pdf</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/272534/5/complex-ls-code.tar">software</a>&nbsp;]
<blockquote>
The problem of solving approximately in the least squares sense an overdetermined linear system of equations with complex valued coefficients is considered, where the elements of the solution vector are constrained to have the same phase. A direct solution to this problem is given in [Linear Algebra and Its Applications, Vol. 433, pp.&nbsp;1719-1721]. An alternative direct solution that reduces the problem to a generalized eigenvalue problem is derived in this paper. The new solution is related to generalized low-rank matrix approximation and makes possible one to use existing robust and efficient algorithms.
</blockquote>
<p><blockquote>
Keywords: Linear system of equations, Phase constraint, Low-rank approximation, Total least squares.
</blockquote>

</td>
</tr>
</table><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.97.</em></p>
